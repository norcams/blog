<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>norcams</title><link href="http://blog.norcams.org/" rel="alternate"></link><link href="http://blog.norcams.org/feeds/bachelor-elasticsearch-logstash.atom.xml" rel="self"></link><id>http://blog.norcams.org/</id><updated>2015-04-20T10:39:00+02:00</updated><entry><title>Day 14: Summary: Collecting OpenStack logs with Logstash</title><link href="http://blog.norcams.org/day-14-summary-collecting-openstack-logs-with-logstash.html" rel="alternate"></link><updated>2015-04-20T10:39:00+02:00</updated><author><name>Kristian Skurtveit</name></author><id>tag:blog.norcams.org,2015-04-20:day-14-summary-collecting-openstack-logs-with-logstash.html</id><summary type="html">&lt;p&gt;This blog post is a summary of the first 14 days of work on my bachelor
degree.&amp;nbsp; It is written in English to satisfy some of our Brazilian
readers at the University in SÃ£o Paulo.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.openstack.org/"&gt;Openstack&lt;/a&gt; consists of many different
services and components, and&amp;nbsp; all of these services are logging
information to their own log files respectively.&amp;nbsp; However, it would be
an impossible job for a system administrator to monitor all of these log
files by simply tailing them through the terminal. This is where
Logstash is useful. Logstash is an open-source tool for managing events
and logs. It is primarily used for collecting logs, parsing them and
save them for later use. The tool also comes with an interface for
searching in the logs you've collected.&lt;/p&gt;
&lt;p&gt;Based on the &lt;a class="reference external" href="https://github.com/norcams/winch"&gt;winch&lt;/a&gt; project on
GitHub I have created a Logstash node where all logs coming from
OpenStack have been centralized. On this node all logs are parsed,
information extracted and saved in Elasticsearch. Seconds after, the
extracted information is visible on the Kibana dashboard (a front-end to
Elasticsearch) ready for searching, filtering and visualization.
Extracting the information from the log files is a bit more complex than
it sounds. However, Logstash is very easy to get started with and once
the basics are covered you're ready to write complex filters yourself.
Having the &lt;a class="reference external" href="http://grokdebug.herokuapp.com/"&gt;grok debugger&lt;/a&gt; in hand
and a quick
&lt;a class="reference external" href="http://www.google.no/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;cad=rja&amp;amp;uact=8&amp;amp;ved=0CB4QtwIwAA&amp;amp;url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYIKm6WUgFTY&amp;amp;ei=coQyVeHILYOtsAGbnoGADQ&amp;amp;usg=AFQjCNHNCs05hUDcTnuyPAcKuiPltMC--A&amp;amp;sig2=62L8IW-f5ply9FM_TA7eUg&amp;amp;bvm=bv.91071109,d.bGg"&gt;tutorial&lt;/a&gt;
in the other also helps :)&lt;/p&gt;
&lt;p&gt;In my configuration I'm pretty much finished with the filters that
covers all the lines of log that the nova services in OpenStack are
generating. Launching, rebooting, deleting instances and error messages
related to instances is now hit by a filter in Logstash and saved for
later searches. Additionally I've made a filter that caches everything
that is not matched by any previous filter in the configuration. This is
in case some special event should occur or if the system goes haywire
(not that I expect that to happen). The 'all-matching' filter is tagged
with &amp;quot;unmatched_event&amp;quot; , and from here we can go back and change the
original filter to take &amp;quot;these&amp;quot; special events into account. By doing
this we will at all times have an overview if something should go wrong.
Also we won't miss any data that somewhat could be important for us to
know. The Logstash configuration can be found
&lt;a class="reference external" href="https://github.com/norcams/winch/blob/stable/icehouse-centos6-monitoring/conf/logstash.conf"&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Further on I've also created some metrics which can been seen in the
configuration file. Winch monitoring also consist of a Graphite node
where these metrics are sent and visualized. I believe that some data
are best when they are graphed in some way or the other providing an
overview on a day-to-day basis (or even minute-to-minute basis)&amp;nbsp; on how
the system is performing. Graphs also helps seeing systems in context
which is very useful.&lt;/p&gt;
&lt;p&gt;During the next couple of weeks I will continue to make filters, extract
data from logs until all OpenStack services are covered, visualize data
and put data in context by making graphs and much more. Stay tuned!&lt;/p&gt;
</summary><category term="elasticsearch"></category><category term="logstash"></category><category term="monitoring"></category></entry></feed>